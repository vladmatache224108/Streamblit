<p><br />REQUIREMENT #7 Accountability<br />The principle of accountability necessitates that mechanisms be put in place to ensure<br />responsibility for the development, deployment and/or use of AI systems. This topic is<br />closely related to risk management, identifying and mitigating risks in a transparent way that<br />can be explained to and audited by third parties. When unjust or adverse impacts occur,<br />accessible mechanisms for accountability should be in place that ensure an adequate<br />possibility of redress.<br />Glossary: Accountability; AI Ethics Review Board; Redress by Design.<br />Auditability<br />This subsection helps to self-assess the existing or necessary level that would be required<br />for an evaluation of the AI system by internal and external auditors. The possibility to<br />conduct evaluations as well as to access records on said evaluations can contribute to<br />Trustworthy AI. In applications affecting fundamental rights, including safety-critical<br />applications, AI systems should be able to be independently audited. This does not<br />necessarily imply that information about business models and intellectual property related to<br />the AI system must always be openly available.<br /><strong> Did you establish mechanisms that facilitate the AI systems auditability<br />(e.g. traceability of the development process, the sourcing of training data and the<br />logging of the AI systems processes, outcomes, positive and negative impact)?</strong></p>
<p>Yes, it is important to establish mechanisms that facilitate the auditability of the AI system, such as traceability of the development process, sourcing of training data, and logging of the AI system's processes, outcomes, and positive and negative impacts. Our team has taken steps by using Trello and GitHub to evidence the whole process.   </p>
<p><br /><strong> Did you ensure that the AI system can be audited by independent third parties?</strong></p>
<p>Yes, it is important to ensure that the AI system can be audited by independent third parties to ensure transparency and accountability. In applications affecting fundamental rights, including safety-critical applications, independent audits should be conducted to ensure the AI system meets ethical and legal standards. This does not necessarily require that information about business models and intellectual property related to the AI system must always be openly available. Our team has taken steps to do this from filling in the DEDA and ALTAI framework.</p>
<p>Risk Management<br />Both the ability to report on actions or decisions that contribute to the AI system's outcome,<br />and to respond to the consequences of such an outcome, must be ensured. Identifying,<br />assessing, documenting and minimising the potential negative impacts of AI systems is<br />especially crucial for those (in)directly affected. Due protection must be available for<br />whistle-blowers, NGOs, trade unions or other entities when reporting legitimate concerns<br />about an AI system.<br />When implementing the above requirements, tensions may arise between them, which may<br />lead to inevitable trade-offs. Such trade-offs should be addressed in a rational and<br />methodological manner within the state of the art. This entails that relevant interests and<br />values implicated by the AI system should be identified and that, if conflict arises, trade-offs<br />should be explicitly acknowledged and evaluated in terms of their risk to safety and ethical<br />principles, including fundamental rights. Any decision about which trade-off to make should<br />be well reasoned and properly documented. When adverse impact occurs, accessible<br />mechanisms should be foreseen that ensure adequate redress.</p>
<p>Did you foresee any kind of external guidance or third-party auditing processes to<br />oversee ethical concerns and accountability measures?<br /><strong>o Does the involvement of these third parties go beyond the development<br />phase?</strong></p>
<p>Yes, involving third parties beyond the development phase is important to ensure ongoing ethical considerations and accountability.</p>
<p><br /><strong> Did you organise risk training and, if so, does this also inform about the potential<br />legal framework applicable to the AI system?</strong></p>
<p>Yes, organising risk training is important to ensure all relevant parties are aware of the potential risks associated with the AI system. This training should also cover the applicable legal framework however we did not have a training seeing how this is a school project.</p>
<p><br /><strong> Did you consider establishing an AI ethics review board or a similar mechanism to<br />discuss the overall accountability and ethics practices, including potential unclear<br />grey areas?</strong></p>
<p>While this may be important for companies, it may not be relevant for a school project.</p>
<p><br /><strong> Did you establish a process to discuss and continuously monitor and assess the AI<br />system's adherence to this Assessment List for Trustworthy AI (ALTAI)?</strong></p>
<p>While this may be important for companies, it may not be relevant for a school project.</p>
<p><br /><strong>o Does this process include identification and documentation of conflicts<br />between the 6 aforementioned requirements or between different ethical<br />principles and explanation of the 'trade-off' decisions made?</strong></p>
<p>While this may be important for companies, it may not be relevant for a school project.</p>
<p><br /><strong>o Did you provide appropriate training to those involved in such a process and<br />does this also cover the legal framework applicable to the AI system?</strong></p>
<p>Yes, it's essential to provide appropriate training to those involved in the process of monitoring and assessing the AI system's adherence, including covering the applicable legal framework for this school project we have not provided appropriate training because it is not applicable.</p>
<p><br /><strong> Did you establish a process for third parties (e.g. suppliers, end-users, subjects,<br />distributors/vendors or workers) to report potential vulnerabilities, risks or biases in<br />the AI system?</strong></p>
<p>Yes, it's important to have a process in place for third parties to report any potential vulnerabilities, risks, or biases in the AI system. This process should also foster revision of the risk management process. This makes it not relevant for us seeing how we dont work that close with third parties that we should take into account risk management.</p>
<p><br /><strong>o Does this process foster revision of the risk management process?</strong></p>
<p>We put in place checks and balances to avoid vulnerabilities that could lead to biases. This leads us to have revisions on our process. </p>
<p><br /><strong> For applications that can adversely affect individuals, have redress by design<br />mechanisms been put in place?</strong></p>
<p>Yes, it's important to have redress by design mechanisms in place for any applications that may have the potential to adversely affect individuals. This includes mechanisms for adequate redress when adverse impacts occur.</p>